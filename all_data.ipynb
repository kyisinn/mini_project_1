{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528e7d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiles saved to Group2_Part1_Profile11.csv\n"
     ]
    }
   ],
   "source": [
    "# build_profiles.py\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "USERS_FILE  = \"UserData.csv\"\n",
    "OUT_FILE    = \"Group2_Part1_Profile11.csv\"   \n",
    "\n",
    "# 1) Load hotel features into a dictionary\n",
    "item_features = {}  # itemid -> list of features\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline() \n",
    "    for line in f:\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        iid = int(parts[0])\n",
    "        features = parts[3].split(\"|\") if parts[3] else []\n",
    "        item_features[iid] = features\n",
    "\n",
    "# 2) Load user->visited items\n",
    "user2items = {}  # userid -> list of itemids\n",
    "with open(USERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) < 2: \n",
    "            continue\n",
    "        uid = int(row[0])\n",
    "        iid = int(row[1])\n",
    "        if uid not in user2items:\n",
    "            user2items[uid] = []\n",
    "        if iid not in user2items[uid]:\n",
    "            user2items[uid].append(iid)\n",
    "\n",
    "#  Pick first 5 users\n",
    "user_ids = sorted(user2items.keys())[:5]\n",
    "\n",
    "#  Build profiles (union of all features of visited hotels)\n",
    "user_profiles = {}\n",
    "for uid in user_ids:\n",
    "    feats = []\n",
    "    for iid in user2items[uid]:\n",
    "        if iid in item_features:\n",
    "            for ftr in item_features[iid]:\n",
    "                if ftr not in feats:\n",
    "                    feats.append(ftr)\n",
    "    user_profiles[uid] = feats\n",
    "\n",
    "# 5) Write profiles to CSV\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userid,features\\n\")\n",
    "    for uid in user_ids:\n",
    "        feats_str = \"|\".join(user_profiles[uid])\n",
    "        f.write(f\"{uid},{feats_str}\\n\")\n",
    "\n",
    "print(\"Profiles saved to\", OUT_FILE)\n",
    "#kldkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d32d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix saved to Group2_Part1_SimMatrix12.csv\n"
     ]
    }
   ],
   "source": [
    "# jaccard_matrix.py\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "PROFILES_FILE = \"Group2_Part1_Profile11.csv\"   \n",
    "USERS_FILE = \"UserData.csv\"\n",
    "OUT_FILE = \"Group2_Part1_SimMatrix12.csv\"\n",
    "\n",
    "# Load hotel features\n",
    "item_features = {}\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    f.readline() \n",
    "    for line in f:\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        iid = int(parts[0])\n",
    "        feats = parts[3].split(\"|\") if parts[3] else []\n",
    "        item_features[iid] = feats\n",
    "\n",
    "all_items = sorted(item_features.keys())\n",
    "\n",
    "# 2) Load user profiles\n",
    "user_profiles = {}\n",
    "with open(PROFILES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    f.readline()  \n",
    "    for line in f:\n",
    "        uid_str, feats_str = line.strip().split(\",\", 1)\n",
    "        uid = int(uid_str)\n",
    "        feats = feats_str.split(\"|\") if feats_str else []\n",
    "        user_profiles[uid] = feats\n",
    "\n",
    "# 3) Load visited hotels\n",
    "user2items = {}\n",
    "with open(USERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    f.readline()  # skip header\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) < 2: continue\n",
    "        uid = int(row[0])\n",
    "        iid = int(row[1])\n",
    "        if uid not in user2items:\n",
    "            user2items[uid] = []\n",
    "        if iid not in user2items[uid]:\n",
    "            user2items[uid].append(iid)\n",
    "\n",
    "# keep the 5 users from profiles file\n",
    "user_ids = sorted(user_profiles.keys())\n",
    "\n",
    "# 4) Jaccard function\n",
    "def jaccard(listA, listB):\n",
    "    setA = set(listA)\n",
    "    setB = set(listB)\n",
    "    if not setA and not setB:\n",
    "        return 0.0\n",
    "    inter = 0\n",
    "    for x in setA:\n",
    "        if x in setB:\n",
    "            inter += 1\n",
    "    union = len(setA) + len(setB) - inter\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return inter / union\n",
    "\n",
    "# 5) Build matrix and write file\n",
    "\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    f.write(\"userid\")\n",
    "    for iid in all_items:\n",
    "        f.write(\",\" + str(iid))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for uid in user_ids:\n",
    "        f.write(str(uid))\n",
    "        for iid in all_items:\n",
    "            if iid in user2items.get(uid, []):\n",
    "                f.write(\",\")   # leave blank for visited\n",
    "            else:\n",
    "                score = jaccard(user_profiles[uid], item_features[iid])\n",
    "                f.write(\",\" + \"{:.6f}\".format(score))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Similarity matrix saved to\", OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2b14ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 recommendations saved to Group2_Part1_Recommendation13.csv\n"
     ]
    }
   ],
   "source": [
    "# top5_recommendations.py\n",
    "\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "SIM_FILE    = \"Group2_Part1_SimMatrix12.csv\"  \n",
    "OUT_FILE    = \"Group2_Part1_Recommendation13.csv\"\n",
    "\n",
    "# 1) Build a lookup: itemid -> (hotelid, hotelname)\n",
    "\n",
    "item_lookup = {}  \n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")  # itemid,hotelid,hotelname,features\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            iid = int(parts[0])\n",
    "        except:\n",
    "            continue\n",
    "        hid_str = parts[1] if len(parts) > 1 else \"\"\n",
    "        hname   = parts[2] if len(parts) > 2 else \"\"\n",
    "        try:\n",
    "            hid = int(hid_str)\n",
    "        except:\n",
    "            hid = 0\n",
    "        item_lookup[iid] = (hid, hname)\n",
    "\n",
    "# 2) Read similarity matrix and compute Top-5 per user\n",
    "\n",
    "recommendations = []  \n",
    "\n",
    "with open(SIM_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    if len(header) <= 1:\n",
    "        pass\n",
    "    else:\n",
    "        item_ids = []\n",
    "        for c in header[1:]:\n",
    "            try:\n",
    "                item_ids.append(int(c))\n",
    "            except:\n",
    "                item_ids.append(None) \n",
    "\n",
    "        for line in f:\n",
    "            row = line.strip().split(\",\")\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            try:\n",
    "                uid = int(row[0])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # Collect (score, itemid) for non-visited cells (non-empty)\n",
    "            scored_items = []\n",
    "            for i in range(1, len(row)):\n",
    "                iid = item_ids[i - 1]  # align with header\n",
    "                if iid is None:\n",
    "                    continue\n",
    "                cell = row[i].strip()\n",
    "                if cell == \"\":  # visited -> left blank\n",
    "                    continue\n",
    "                # parse similarity\n",
    "                try:\n",
    "                    s = float(cell)\n",
    "                except:\n",
    "                    continue\n",
    "                scored_items.append((s, iid))\n",
    "\n",
    "            # Sort: highest similarity first, then smaller itemid\n",
    "            # (negative score for descending sort without imports)\n",
    "            for j in range(len(scored_items) - 1):\n",
    "                # simple bubble-sort style to avoid imports; fine for small lists\n",
    "                for k in range(len(scored_items) - 1 - j):\n",
    "                    s1, id1 = scored_items[k]\n",
    "                    s2, id2 = scored_items[k + 1]\n",
    "                    swap = False\n",
    "                    if s2 > s1:\n",
    "                        swap = True\n",
    "                    elif s2 == s1 and id2 < id1:\n",
    "                        swap = True\n",
    "                    if swap:\n",
    "                        tmp = scored_items[k]\n",
    "                        scored_items[k] = scored_items[k + 1]\n",
    "                        scored_items[k + 1] = tmp\n",
    "\n",
    "            # Take Top-5\n",
    "            limit = 5 if len(scored_items) >= 5 else len(scored_items)\n",
    "            for t in range(limit):\n",
    "                s, iid = scored_items[t]\n",
    "                hid, hname = item_lookup.get(iid, (0, \"\"))\n",
    "                recommendations.append((uid, iid, hid, hname, s))\n",
    "\n",
    "# 3) Write output CSV\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userid,itemid,hotelid,hotelname,similarity\\n\")\n",
    "    for (uid, iid, hid, hname, s) in recommendations:\n",
    "        # Ensure commas in hotel names won't break CSV too badly:\n",
    "        # (basic handling; if you need full CSV quoting you'd implement manual quoting)\n",
    "        hname_clean = hname.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        f.write(str(uid)); f.write(\",\")\n",
    "        f.write(str(iid)); f.write(\",\")\n",
    "        f.write(str(hid)); f.write(\",\")\n",
    "        f.write(hname_clean); f.write(\",\")\n",
    "        f.write(\"{:.6f}\".format(s)); f.write(\"\\n\")\n",
    "\n",
    "print(\"Top-5 recommendations saved to\", OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e87861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiles saved to Group2_Part1_Profile11.csv\n"
     ]
    }
   ],
   "source": [
    "# build_profiles.py\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "USERS_FILE  = \"UserData.csv\"\n",
    "OUT_FILE    = \"Group2_Part1_Profile11.csv\"   \n",
    "\n",
    "# 1) Load hotel features into a dictionary\n",
    "item_features = {}  # itemid -> list of features\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline() \n",
    "    for line in f:\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        iid = int(parts[0])\n",
    "        features = parts[3].split(\"|\") if parts[3] else []\n",
    "        item_features[iid] = features\n",
    "\n",
    "# 2) Load user->visited items\n",
    "user2items = {}  # userid -> list of itemids\n",
    "with open(USERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) < 2: \n",
    "            continue\n",
    "        uid = int(row[0])\n",
    "        iid = int(row[1])\n",
    "        if uid not in user2items:\n",
    "            user2items[uid] = []\n",
    "        if iid not in user2items[uid]:\n",
    "            user2items[uid].append(iid)\n",
    "\n",
    "#  Pick first 5 users\n",
    "user_ids = sorted(user2items.keys())[:5]\n",
    "\n",
    "#  Build profiles (union of all features of visited hotels)\n",
    "user_profiles = {}\n",
    "for uid in user_ids:\n",
    "    feats = []\n",
    "    for iid in user2items[uid]:\n",
    "        if iid in item_features:\n",
    "            for ftr in item_features[iid]:\n",
    "                if ftr not in feats:\n",
    "                    feats.append(ftr)\n",
    "    user_profiles[uid] = feats\n",
    "\n",
    "# 5) Write profiles to CSV\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userid,features\\n\")\n",
    "    for uid in user_ids:\n",
    "        feats_str = \"|\".join(user_profiles[uid])\n",
    "        f.write(f\"{uid},{feats_str}\\n\")\n",
    "\n",
    "print(\"Profiles saved to\", OUT_FILE)\n",
    "#kldkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50167493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part II profiles saved to Group2_Part2_Profile21.csv\n"
     ]
    }
   ],
   "source": [
    "# build_profiles_part2.py\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "USERS_FILE  = \"UserData.csv\"\n",
    "OUT_FILE    = \"Group2_Part2_Profile21.csv\"   # change Group1 -> your group number\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def split_features(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    parts = s.split(\"|\")\n",
    "    # de-duplicate within one item\n",
    "    uniq = []\n",
    "    seen = {}\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if p and (p not in seen):\n",
    "            seen[p] = True\n",
    "            uniq.append(p)\n",
    "    return uniq\n",
    "\n",
    "# ---------- 1) DF per feature ----------\n",
    "feature_df = {}      # feature -> document frequency\n",
    "item_features = {}   # itemid -> list of unique features\n",
    "N_items = 0\n",
    "\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline()  # skip header line\n",
    "    for line in f:\n",
    "        cols = line.rstrip(\"\\n\").split(\",\")\n",
    "        if len(cols) < 4:\n",
    "            continue\n",
    "        try:\n",
    "            iid = int(cols[0])\n",
    "        except:\n",
    "            continue\n",
    "        feats = split_features(cols[3])\n",
    "        item_features[iid] = feats\n",
    "        N_items += 1\n",
    "        # update DF (count each feature once per item)\n",
    "        seen_local = {}\n",
    "        for ft in feats:\n",
    "            if ft not in seen_local:\n",
    "                seen_local[ft] = True\n",
    "                feature_df[ft] = feature_df.get(ft, 0) + 1\n",
    "\n",
    "# ---------- 2) IDF ----------\n",
    "idf = {}  # feature -> idf weight (N_items / df)\n",
    "for ft in feature_df:\n",
    "    df = feature_df[ft]\n",
    "    if df <= 0:\n",
    "        idf[ft] = 0.0\n",
    "    else:\n",
    "        # simple inverse frequency (no log, no imports)\n",
    "        idf[ft] = float(N_items) / float(df)\n",
    "\n",
    "# ---------- 3) Item vectors (binary TF × IDF) ----------\n",
    "item_vector = {}  # itemid -> dict(feature -> weight)\n",
    "for iid in item_features:\n",
    "    feats = item_features[iid]\n",
    "    vec = {}\n",
    "    for ft in feats:\n",
    "        vec[ft] = idf.get(ft, 0.0)  # TF is 1 for present features\n",
    "    item_vector[iid] = vec\n",
    "\n",
    "# ---------- 4) Load user visits; pick first 5 users ----------\n",
    "user2items = {}  # userid -> list of visited iids\n",
    "with open(USERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    # try to locate columns robustly\n",
    "    # expect 'userid' and 'itemid' or ' itemid' depending on file\n",
    "    try:\n",
    "        uid_idx = header.index(\"userid\")\n",
    "    except:\n",
    "        uid_idx = 0\n",
    "    # find the itemid-ish column\n",
    "    iid_idx = -1\n",
    "    for i in range(len(header)):\n",
    "        h = header[i].strip().lower()\n",
    "        if \"itemid\" in h:\n",
    "            iid_idx = i\n",
    "            break\n",
    "    if iid_idx == -1:\n",
    "        iid_idx = 1  # fallback\n",
    "\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) <= iid_idx:\n",
    "            continue\n",
    "        try:\n",
    "            uid = int(row[uid_idx])\n",
    "            iid = int(row[iid_idx])\n",
    "        except:\n",
    "            continue\n",
    "        if uid not in user2items:\n",
    "            user2items[uid] = []\n",
    "        # avoid duplicates\n",
    "        if iid not in user2items[uid]:\n",
    "            user2items[uid].append(iid)\n",
    "\n",
    "# choose first 5 user IDs that appear\n",
    "all_user_ids = sorted(user2items.keys())\n",
    "user_ids = all_user_ids[:5]\n",
    "\n",
    "# ---------- 5) Build centroid profile per user ----------\n",
    "user_profile = {}  # userid -> dict(feature -> avg weight)\n",
    "\n",
    "for uid in user_ids:\n",
    "    visited = user2items.get(uid, [])\n",
    "    count = 0\n",
    "    acc = {}  # feature -> sum of weights across visited items\n",
    "    for iid in visited:\n",
    "        vec = item_vector.get(iid)\n",
    "        if not vec:\n",
    "            continue\n",
    "        count += 1\n",
    "        # add vector\n",
    "        for ft in vec:\n",
    "            acc[ft] = acc.get(ft, 0.0) + vec[ft]\n",
    "\n",
    "    # average\n",
    "    prof = {}\n",
    "    if count > 0:\n",
    "        for ft in acc:\n",
    "            prof[ft] = acc[ft] / float(count)\n",
    "    # store\n",
    "    user_profile[uid] = prof\n",
    "\n",
    "# ---------- 6) Write Part II profiles ----------\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userid,features\\n\")\n",
    "    for uid in user_ids:\n",
    "        prof = user_profile.get(uid, {})\n",
    "        # turn into token:weight, sorted by descending weight then token\n",
    "        items = []\n",
    "        # simple list + manual sort (bubble) to avoid imports\n",
    "        for ft in prof:\n",
    "            items.append((ft, prof[ft]))\n",
    "\n",
    "        # sort by (-weight, token)\n",
    "        n = len(items)\n",
    "        for i in range(n - 1):\n",
    "            for j in range(n - 1 - i):\n",
    "                ft1, w1 = items[j]\n",
    "                ft2, w2 = items[j + 1]\n",
    "                swap = False\n",
    "                if w2 > w1:\n",
    "                    swap = True\n",
    "                elif w2 == w1 and ft2 < ft1:\n",
    "                    swap = True\n",
    "                if swap:\n",
    "                    tmp = items[j]\n",
    "                    items[j] = items[j + 1]\n",
    "                    items[j + 1] = tmp\n",
    "\n",
    "        # format: token:weight\n",
    "        parts = []\n",
    "        for (ft, w) in items:\n",
    "            parts.append(ft + \":\" + (\"{:.6f}\".format(w)))\n",
    "        f.write(str(uid) + \",\" + \"|\".join(parts) + \"\\n\")\n",
    "\n",
    "print(\"Part II profiles saved to\", OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0b72f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part II model (similarity matrix) saved to Group2_Part2_Model22.csv\n"
     ]
    }
   ],
   "source": [
    "# build_model_part2.py\n",
    "HOTELS_FILE   = \"hotels_processed.csv\"\n",
    "USERS_FILE    = \"UserData.csv\"\n",
    "PROFILES_FILE = \"Group2_Part2_Profile21.csv\"   # change Group1 -> your group number\n",
    "OUT_FILE      = \"Group2_Part2_Model22.csv\"     # change Group1 -> your group number\n",
    "\n",
    "# -------- helpers --------\n",
    "def split_features(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    parts = s.split(\"|\")\n",
    "    uniq = []\n",
    "    seen = {}\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if p and (p not in seen):\n",
    "            seen[p] = True\n",
    "            uniq.append(p)\n",
    "    return uniq\n",
    "\n",
    "def parse_weighted_features(s):\n",
    "    # \"token:weight|token:weight|...\"\n",
    "    feats = {}\n",
    "    if not s:\n",
    "        return feats\n",
    "    parts = s.split(\"|\")\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        # split on last \":\" to be robust if token ever contains \":\"\n",
    "        idx = p.rfind(\":\")\n",
    "        if idx <= 0:\n",
    "            continue\n",
    "        token = p[:idx]\n",
    "        w_str = p[idx+1:]\n",
    "        try:\n",
    "            w = float(w_str)\n",
    "        except:\n",
    "            w = 0.0\n",
    "        feats[token] = w\n",
    "    return feats\n",
    "\n",
    "def dot(a, b):\n",
    "    # a, b are dict(token -> weight)\n",
    "    s = 0.0\n",
    "    # iterate smaller dict for efficiency\n",
    "    if len(a) > len(b):\n",
    "        small = b; large = a\n",
    "    else:\n",
    "        small = a; large = b\n",
    "    for k in small:\n",
    "        if k in large:\n",
    "            s += small[k] * large[k]\n",
    "    return s\n",
    "\n",
    "def norm_sq(a):\n",
    "    s = 0.0\n",
    "    for k in a:\n",
    "        s += a[k] * a[k]\n",
    "    return s\n",
    "\n",
    "def cosine(a, b):\n",
    "    # handle zero norms\n",
    "    na = norm_sq(a)\n",
    "    nb = norm_sq(b)\n",
    "    if na <= 0.0 or nb <= 0.0:\n",
    "        return 0.0\n",
    "    return dot(a, b) / ((na ** 0.5) * (nb ** 0.5))\n",
    "\n",
    "# -------- 1) Build DF for features & collect item features --------\n",
    "feature_df = {}     # feature -> number of items containing it\n",
    "item_features = {}  # itemid -> list of unique features\n",
    "N_items = 0\n",
    "\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    f.readline()  # skip header\n",
    "    for line in f:\n",
    "        cols = line.rstrip(\"\\n\").split(\",\")\n",
    "        if len(cols) < 4:\n",
    "            continue\n",
    "        try:\n",
    "            iid = int(cols[0])\n",
    "        except:\n",
    "            continue\n",
    "        feats = split_features(cols[3])\n",
    "        item_features[iid] = feats\n",
    "        N_items += 1\n",
    "        seen_local = {}\n",
    "        for ft in feats:\n",
    "            if ft not in seen_local:\n",
    "                seen_local[ft] = True\n",
    "                feature_df[ft] = feature_df.get(ft, 0) + 1\n",
    "\n",
    "# -------- 2) IDF and item vectors (TF is binary) --------\n",
    "idf = {}  # feature -> N_items / df\n",
    "for ft in feature_df:\n",
    "    df = feature_df[ft]\n",
    "    if df <= 0:\n",
    "        idf[ft] = 0.0\n",
    "    else:\n",
    "        idf[ft] = float(N_items) / float(df)\n",
    "\n",
    "item_vector = {}  # itemid -> dict(feature -> weight)\n",
    "for iid in item_features:\n",
    "    feats = item_features[iid]\n",
    "    vec = {}\n",
    "    for ft in feats:\n",
    "        vec[ft] = idf.get(ft, 0.0)\n",
    "    item_vector[iid] = vec\n",
    "\n",
    "# -------- 3) Load visited items per user --------\n",
    "user2items = {}  # userid -> list of visited itemids\n",
    "with open(USERS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    # locate columns\n",
    "    try:\n",
    "        uid_idx = header.index(\"userid\")\n",
    "    except:\n",
    "        uid_idx = 0\n",
    "    iid_idx = -1\n",
    "    for i in range(len(header)):\n",
    "        if \"itemid\" in header[i].strip().lower():\n",
    "            iid_idx = i\n",
    "            break\n",
    "    if iid_idx == -1:\n",
    "        iid_idx = 1\n",
    "\n",
    "    for line in f:\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) <= iid_idx:\n",
    "            continue\n",
    "        try:\n",
    "            uid = int(row[uid_idx])\n",
    "            iid = int(row[iid_idx])\n",
    "        except:\n",
    "            continue\n",
    "        if uid not in user2items:\n",
    "            user2items[uid] = []\n",
    "        if iid not in user2items[uid]:\n",
    "            user2items[uid].append(iid)\n",
    "\n",
    "# -------- 4) Load Part II user profiles (weighted) --------\n",
    "user_profile = {}  # userid -> dict(feature -> weight)\n",
    "user_ids = []\n",
    "\n",
    "with open(PROFILES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    f.readline()  # skip header\n",
    "    for line in f:\n",
    "        # split only on first comma to keep feature string intact\n",
    "        idx = line.find(\",\")\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        uid_str = line[:idx].strip()\n",
    "        feats_str = line[idx+1:].strip()\n",
    "        try:\n",
    "            uid = int(uid_str)\n",
    "        except:\n",
    "            continue\n",
    "        prof = parse_weighted_features(feats_str)\n",
    "        user_profile[uid] = prof\n",
    "        user_ids.append(uid)\n",
    "\n",
    "# -------- 5) Build cosine similarity matrix & write CSV --------\n",
    "# Columns are sorted itemids\n",
    "all_items = []\n",
    "for iid in item_vector:\n",
    "    all_items.append(iid)\n",
    "# manual sort\n",
    "for i in range(len(all_items)-1):\n",
    "    for j in range(len(all_items)-1-i):\n",
    "        if all_items[j+1] < all_items[j]:\n",
    "            tmp = all_items[j]\n",
    "            all_items[j] = all_items[j+1]\n",
    "            all_items[j+1] = tmp\n",
    "\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    # header row\n",
    "    f.write(\"userid\")\n",
    "    for iid in all_items:\n",
    "        f.write(\",\" + str(iid))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for uid in user_ids:\n",
    "        f.write(str(uid))\n",
    "        visited = user2items.get(uid, [])\n",
    "        prof = user_profile.get(uid, {})\n",
    "        for iid in all_items:\n",
    "            if iid in visited:\n",
    "                # blank for visited items\n",
    "                f.write(\",\")\n",
    "            else:\n",
    "                vec = item_vector.get(iid, {})\n",
    "                sim = cosine(prof, vec)\n",
    "                f.write(\",\" + \"{:.6f}\".format(sim))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Part II model (similarity matrix) saved to\", OUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51581e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recommendations saved to Group2_Part2_Recommendation23.csv\n"
     ]
    }
   ],
   "source": [
    "# top10_part2.py\n",
    "HOTELS_FILE = \"hotels_processed.csv\"\n",
    "MODEL_FILE  = \"Group2_Part2_Model22.csv\"     # change Group1 -> your group number\n",
    "OUT_FILE    = \"Group2_Part2_Recommendation23.csv\"\n",
    "\n",
    "# 1) Build lookup: itemid -> (hotelid, hotelname)\n",
    "item_lookup = {}  # int -> (int, str)\n",
    "with open(HOTELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")  # itemid,hotelid,hotelname,features\n",
    "    for line in f:\n",
    "        parts = line.rstrip(\"\\n\").split(\",\")\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        # parse ids safely\n",
    "        try: \n",
    "            iid = int(parts[0])\n",
    "        except:\n",
    "            continue\n",
    "        hid = 0\n",
    "        if parts[1].strip() != \"\":\n",
    "            try:\n",
    "                hid = int(parts[1])\n",
    "            except:\n",
    "                hid = 0\n",
    "        hname = parts[2].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        item_lookup[iid] = (hid, hname)\n",
    "\n",
    "# 2) Read similarity matrix and compute Top-10 per user\n",
    "recs = []  # (userid, itemid, hotelid, hotelname, similarity)\n",
    "\n",
    "with open(MODEL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    # header: userid,<itemid1>,<itemid2>,...\n",
    "    header = f.readline().strip().split(\",\")\n",
    "    if len(header) <= 1:\n",
    "        pass\n",
    "    else:\n",
    "        # parse item ids for columns\n",
    "        item_ids = []\n",
    "        for c in header[1:]:\n",
    "            c = c.strip()\n",
    "            try:\n",
    "                item_ids.append(int(c))\n",
    "            except:\n",
    "                item_ids.append(None)  # keep alignment\n",
    "\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            row = line.rstrip(\"\\n\").split(\",\")\n",
    "            # first col is userid\n",
    "            try:\n",
    "                uid = int(row[0].strip())\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # collect (score, itemid) for non-empty cells\n",
    "            scored = []\n",
    "            for i in range(1, len(row)):\n",
    "                iid = item_ids[i - 1]\n",
    "                if iid is None:\n",
    "                    continue\n",
    "                cell = row[i].strip()\n",
    "                if cell == \"\":\n",
    "                    # blank means visited in our pipeline -> skip\n",
    "                    continue\n",
    "                # parse similarity float\n",
    "                try:\n",
    "                    s = float(cell)\n",
    "                except:\n",
    "                    continue\n",
    "                scored.append((s, iid))\n",
    "\n",
    "            # sort scored by similarity desc, then itemid asc — manual bubble sort (no imports)\n",
    "            n = len(scored)\n",
    "            for a in range(n - 1):\n",
    "                for b in range(n - 1 - a):\n",
    "                    s1, id1 = scored[b]\n",
    "                    s2, id2 = scored[b + 1]\n",
    "                    swap = False\n",
    "                    if s2 > s1:\n",
    "                        swap = True\n",
    "                    elif s2 == s1 and id2 < id1:\n",
    "                        swap = True\n",
    "                    if swap:\n",
    "                        tmp = scored[b]\n",
    "                        scored[b] = scored[b + 1]\n",
    "                        scored[b + 1] = tmp\n",
    "\n",
    "            # take Top-10\n",
    "            limit = 10 if n >= 10 else n\n",
    "            for t in range(limit):\n",
    "                s, iid = scored[t]\n",
    "                hid, hname = item_lookup.get(iid, (0, \"\"))\n",
    "                recs.append((uid, iid, hid, hname, s))\n",
    "\n",
    "# 3) Write output CSV\n",
    "with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"userid,itemid,hotelid,hotelname,similarity\\n\")\n",
    "    for (uid, iid, hid, hname, s) in recs:\n",
    "        # basic cleaning in case hotelname has commas or newlines already removed\n",
    "        name = hname.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        f.write(str(uid)); f.write(\",\")\n",
    "        f.write(str(iid)); f.write(\",\")\n",
    "        f.write(str(hid)); f.write(\",\")\n",
    "        f.write(name); f.write(\",\")\n",
    "        f.write(\"{:.6f}\".format(s)); f.write(\"\\n\")\n",
    "\n",
    "print(\"Top-10 recommendations saved to\", OUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
